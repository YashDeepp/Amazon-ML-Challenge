{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oy0tePbBcTtb"},"outputs":[],"source":["import pandas as pd\n","import pyarrow as pa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJtnfblQc9sT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682145805230,"user_tz":-330,"elapsed":2,"user":{"displayName":"akgec CLG","userId":"12999759869900147712"}},"outputId":"64e79204-165d-4749-c580-5542c209e32e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyarrow.lib.MemoryMappedFile at 0x7f53f0975b80>"]},"metadata":{},"execution_count":5}],"source":[]},{"cell_type":"code","source":["import pandas as pd\n","import pyarrow as pa\n","\n","print(\"Reading arrow file...\")\n","mmap = pa.memory_map('/content/drive/MyDrive/Amazon ML Challenge/amazon_ml_challenge_cleaned_dataset/amazon_ml_challenge_cleaned_dataset/train/data-00000-of-00001.arrow')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V6lyMWLypfc7","executionInfo":{"status":"ok","timestamp":1682152281725,"user_tz":-330,"elapsed":3,"user":{"displayName":"akgec CLG","userId":"12999759869900147712"}},"outputId":"8bd04894-fc45-4b7f-cab0-d20d6becacab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading arrow file...\n"]}]},{"cell_type":"code","source":["from pyarrow import json\n","fn='/content/drive/MyDrive/Amazon ML Challenge/amazon_ml_challenge_cleaned_dataset/amazon_ml_challenge_cleaned_dataset/train/state.json'\n","table = json.read_json(fn)\n","table"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YvFu13Vc6EIC","executionInfo":{"status":"ok","timestamp":1682152211163,"user_tz":-330,"elapsed":3,"user":{"displayName":"akgec CLG","userId":"12999759869900147712"}},"outputId":"333fba81-40a0-4b4a-973a-f60b5d52b862"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pyarrow.Table\n","_data_files: list<item: struct<filename: string>>\n","  child 0, item: struct<filename: string>\n","      child 0, filename: string\n","_fingerprint: string\n","_format_columns: null\n","_format_kwargs: struct<>\n","_format_type: null\n","_output_all_columns: bool\n","_split: null\n","----\n","_data_files: [[    -- is_valid: all not null\n","    -- child 0 type: string\n","[\"data-00000-of-00001.arrow\"]]]\n","_fingerprint: [[\"ab0df949184ea6e4\"]]\n","_format_columns: [1 nulls]\n","_format_kwargs: [\n","  -- is_valid: all not null]\n","_format_type: [1 nulls]\n","_output_all_columns: [[false]]\n","_split: [1 nulls]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["import pyarrow.parquet as pq\n","\n","table = pq.read_table('/content/drive/MyDrive/Amazon ML Challenge/amazon_ml_challenge_cleaned_dataset/amazon_ml_challenge_cleaned_dataset/train/data-00000-of-00001.arrow')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"id":"rBwEa7-e6EEw","executionInfo":{"status":"error","timestamp":1682152441244,"user_tz":-330,"elapsed":642,"user":{"displayName":"akgec CLG","userId":"12999759869900147712"}},"outputId":"f20cba6a-1698-4d72-9831-1bc3436eb621"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ArrowInvalid","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-a3491e77fd68>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Amazon ML Challenge/amazon_ml_challenge_cleaned_dataset/amazon_ml_challenge_cleaned_dataset/train/data-00000-of-00001.arrow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2778\u001b[0m             )\n\u001b[1;32m   2779\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2780\u001b[0;31m             dataset = _ParquetDatasetV2(\n\u001b[0m\u001b[1;32m   2781\u001b[0m                 \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2782\u001b[0m                 \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, schema, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m             self._dataset = ds.FileSystemDataset(\n\u001b[0;32m-> 2368\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0mfragment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfragment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphysical_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2369\u001b[0m                 \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparquet_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfragment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilesystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Fragment.physical_schema.__get__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;31mArrowInvalid\u001b[0m: Could not open Parquet input source '/content/drive/MyDrive/Amazon ML Challenge/amazon_ml_challenge_cleaned_dataset/amazon_ml_challenge_cleaned_dataset/train/data-00000-of-00001.arrow': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file."]}]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","from pandarallel import pandarallel\n","from sklearn.preprocessing import MinMaxScaler\n","\n","pandarallel.initialize(progress_bar=False, nb_workers=64)"],"metadata":{"id":"IJ1zuHDh6EB_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682163697619,"user_tz":-330,"elapsed":730,"user":{"displayName":"akgec CLG","userId":"12999759869900147712"}},"outputId":"e71823e2-fb7e-4126-8a40-5012b5f4e659"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO: Pandarallel will run on 64 workers.\n","INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"]}]},{"cell_type":"code","source":["!pip install pandarallel "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqKuCjMcxI-t","executionInfo":{"status":"ok","timestamp":1682163683165,"user_tz":-330,"elapsed":4931,"user":{"displayName":"akgec CLG","userId":"12999759869900147712"}},"outputId":"757392f0-5991-4ba2-c79d-b717f7e0d164"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pandarallel\n","  Downloading pandarallel-1.6.4.tar.gz (12 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting dill>=0.3.1\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1 in /usr/local/lib/python3.9/dist-packages (from pandarallel) (1.5.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from pandarallel) (5.9.5)\n","Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=1->pandarallel) (1.22.4)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1->pandarallel) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1->pandarallel) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1->pandarallel) (1.16.0)\n","Building wheels for collected packages: pandarallel\n","  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pandarallel: filename=pandarallel-1.6.4-py3-none-any.whl size=16677 sha256=3c5e8cf9066601a1a75041100f68339a5e297d20b510389c79aae23933cbc5b5\n","  Stored in directory: /root/.cache/pip/wheels/41/01/29/deaa71fe596f8d857e57c4fb388db8861e23e6ed0b03204dcb\n","Successfully built pandarallel\n","Installing collected packages: dill, pandarallel\n","Successfully installed dill-0.3.6 pandarallel-1.6.4\n"]}]},{"cell_type":"code","source":["# Define a function to remove URLs, emojis, and emoticons from a given text\n","def _clean_text(text):\n","    # Handle cases where the input is None or NaN\n","    if text is None or pd.isna(text):\n","        return ''\n","    \n","    # Remove URLs\n","    text = re.sub(r'http\\S+', '', text)\n","\n","    # Define the set of allowed characters (ASCII characters plus the specified exceptions).\n","    allowed_chars = r'a-zA-Z0-9+\\-_=:,. '\n","\n","    # Use a regular expression to remove any character that is not in the allowed set.\n","    cleaned_text = re.sub(f'[^{allowed_chars}]', '', text)\n","    \n","    return cleaned_text\n","\n","# Define a function to check if the number of digits is greater than the number of alphabetic characters\n","def _more_numbers_than_alphabets(row):\n","    text = ' '.join(row)\n","    num_digits = sum(char.isdigit() for char in text)\n","    num_alpha = sum(char.isalpha() for char in text)\n","    return num_digits > num_alpha\n","\n","def sanitise_data(df):\n","    df['TITLE'] = df['TITLE'].parallel_apply(_clean_text)\n","    df['BULLET_POINTS'] = df['BULLET_POINTS'].parallel_apply(_clean_text)\n","    df['DESCRIPTION'] = df['DESCRIPTION'].parallel_apply(_clean_text)\n","\n","    # Filter out rows where the number of digits is greater than the number of alphabetic characters\n","    df = df[~df[['TITLE', 'BULLET_POINTS', 'DESCRIPTION']].parallel_apply(_more_numbers_than_alphabets, axis=1)]\n","\n","    # scaler = MinMaxScaler()\n","    # df[[\"PRODUCT_LENGTH\"]] = scaler.fit_transform(df[[\"PRODUCT_LENGTH\"]])\n","    return df\n","def sample_data(df, n):\n","    new_df = df.sample(n=n, random_state=42)\n","    new_df.reset_index(drop=True, inplace=True)\n","    return new_df"],"metadata":{"id":"evUBf3_FplgZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = pd.read_csv('/content/drive/MyDrive/Amazon ML Challenge/dataset/train.csv')\n","sampled_dataset = sample_data(dataset, 800_000)\n","santised_dataset = sanitise_data(sampled_dataset)"],"metadata":{"id":"t8WGMj2sxWlv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["santised_dataset.to_csv('data.csv')"],"metadata":{"id":"low7isNZ2l-W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp data.csv \"drive/My Drive/\""],"metadata":{"id":"bZXjU3db3YH_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ld3WmAi-39yf"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1PKHNOU7a83gaQ2fsH5fpVwVnCGWo__LF","authorship_tag":"ABX9TyOTnyvgVM1mNE4Ms0u40lKO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}